--------------------------------------------------------------------------------
Title: Exploring the Global Impact of Pandemics: A Data-Driven Analysis with a Focus on COVID-19 (2024)
Author: 710008257
Date: 2024-04-22
--------------------------------------------------------------------------------

## Introduction

Welcome to my data-driven blog. This project features interactive plots generated from thorough data analysis, aimed at exploring the impact, primarily in terms of death toll, of both historical and current pandemics.

Initially, the project provides a concise overview by examining pandemics that have had the highest and lowest death tolls, as well as their progression over time. Additionally, the geographical distribution of pandemics is visualised on a map to offer a spatial understanding of the data.

Moving forward, the focus shifts to a closer examination of COVID-19, exploring its effects based on age, sex, and region. Subsequently, employing the random forest technique, we delve into how various ethnic groups have been affected.

Lastly, the project culminates in a final prediction, where we assess the predicted ratio of COVID deaths to all deaths for a group sharing similar characteristics to myself. This well-rounded approach and narrative of the project follows logical steps of my interest in the topic, with the ultimate goal of better understanding how in the future we can shape public policies to combat regions/ specific groups which are particularly vulnerable to a greater death toll in the face of pandemics.

...

## Repository overview
This repository is structured as follows:

├── README
├── Econ_Final_project_Blog.html
├── Final Project Code.ipynb
├── DataSets
├── Plots
├── .ipynb_checkpoints
├── blog.txt
├── .DS_Store
├── .gitatrributes




All data is contained in the DataSets folder which was used in the 'Final Project Code.ipynb' were all code can be found. The plots are saved automatically as html file when the code is run. The blog 'Econ_Final_project_Blog.html' was written in html in a text editor and includes my analysis and plots. blog.tex file contains the link to the Github repository.

## Running instructions

To successfully run the project, begin by cloning the repository from GitHub to your local machine. Make certain that you have all the required Python packages installed as indicated in the list. It's crucial to maintain a stable internet connection to ensure the proper functioning of the web scraping process. Next, execute the "Final Project Code.ipynb" Jupyter notebook to initiate the code execution and generate the necessary plots. Lastly, for a comprehensive analysis and detailed findings, refer to the blog post titled "Econ_Final_project_Blog.html".
  
Within python (Jupyter Notebook) , a number of additional libraries are required. 
Here's a list of Python libraries that I've imported in my project:

requests: Used for making HTTP requests.
BeautifulSoup (from bs4): Used for web scraping and parsing HTML.
pandas: Used for data manipulation and analysis.
numpy: Used for numerical computing and arrays.
re: Used for regular expressions.
plotly.express (from plotly): Used for interactive visualization.
plotly.io (from plotly): Used for Plotly I/O operations.
geopy: Used for geocoding and working with geographic data.
Nominatim (from geopy.geocoders): A geocoder service for OpenStreetMap.
sklearn.model_selection.train_test_split: Used for splitting datasets into training and testing sets.
sklearn.ensemble.RandomForestRegressor: Used for building a random forest regression model.
sklearn.metrics.mean_absolute_error, sklearn.metrics.mean_squared_error, sklearn.metrics.r2_score: Used for evaluating regression model performance.


## About

This repository was generated by Rhianna Sookhy.  For queries:
 mail to: rs918@exeter.ac.uk